{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "12.4\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "cuda\n",
      "0\n",
      "0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())\n",
    "print(torch.cuda.empty_cache())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Variable's Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9805, 0.9989, 0.7576],\n",
      "        [0.2057, 0.5865, 0.5063],\n",
      "        [0.3485, 0.1318, 0.9407]])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,3)\n",
    "print(x)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = x.to(device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed Of CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cpu = torch.rand(10000,10000)\n",
    "x_gpu =  x_cpu.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time: 4.7554 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_cpu = x_cpu @ x_cpu\n",
    "end = time.time()\n",
    "print(f\"CPU Time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time: 0.1288 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "y_gpu = x_gpu @ x_gpu\n",
    "end = time.time()\n",
    "print(f\"GPU Time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activate Benchmark of cuDNN (Accelerating training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn On/Off Mixed Precision Training (Save VRAM and Accelerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Component | Purpose |\n",
    "|:---|:---|\n",
    "| `autocast` | Automatically selects float16/float32 to accelerate training and reduce VRAM usage. |\n",
    "| `GradScaler` | Scales the loss to prevent numerical underflow when using float16 during training. |\n",
    "\n",
    "**NOTE**: See more in [AI/Utils/Mixed-Precision-Training](AI/Utils/Mixed-Precision-Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 5)\n",
    ")\n",
    "model = model.cuda() # -> Move model to GPU\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "input = torch.randn(32,784).cuda()\n",
    "target = torch.randint(0, 5, (32,)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.5728\n",
      "Epoch 2: Loss = 1.0307\n",
      "Epoch 3: Loss = 0.6581\n",
      "Epoch 4: Loss = 0.4125\n",
      "Epoch 5: Loss = 0.2567\n",
      "Total time:  0.0367 seconds\n"
     ]
    }
   ],
   "source": [
    "# Without Mixed Precision Training\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(input) # Forward pass\n",
    "    loss = loss_fn(output, target)\n",
    "\n",
    "    loss.backward() # Backward pass\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total time:  {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1596\n",
      "Epoch 2: Loss = 0.0995\n",
      "Epoch 3: Loss = 0.0627\n",
      "Epoch 4: Loss = 0.0401\n",
      "Epoch 5: Loss = 0.0262\n",
      "Total time:  0.0079 seconds\n"
     ]
    }
   ],
   "source": [
    "# With Mixed Precision Training\n",
    "\n",
    "start_time = time.time()\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.amp.autocast(device_type=\"cuda\"):\n",
    "        output = model(input) # Forward pass\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "    scaler.scale(loss).backward() # Backward pass\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total time:  {end_time - start_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
